## 论文翻译
### Introduction
引言

病毒是地球上最丰富的生物实体，存在于每一个生态系统中。理解病毒如何调节微生物群落动态和功能输出是一个涉及从全球生物地球化学到人类健康和疾病等多个层面的活跃研究领域。尽管病毒数量庞大且影响深远，但由于病毒的巨大遗传多样性，以及大多数基因组学工具依赖于与现有参考数据库的序列相似性，综合性大规模的病毒宏基因组学（viromics）研究受到了严重阻碍。这些问题还因病毒中缺乏普遍基因而加剧，使得在多样化的病毒群体中进行系统发育和比较分析变得复杂。总体而言，这些挑战阻碍了既准确又可扩展到日益多样化的病毒数据集的宏基因组学软件的开发。因此，迫切需要开发基于数据驱动的框架，使用可泛化的基因组学原则而非简单的序列同源性方法来研究病毒。

蛋白质语言模型（pLMs）是用于可泛化基因组学的有前途的深度学习框架。在数百万蛋白质的语料库上训练的pLMs已被证明能够像读句子中的单词一样模拟蛋白质序列中的氨基酸模式，利用蛋白质内的氨基酸的上下文信息捕捉蛋白质的生化、功能和结构特征。将pLMs应用于病毒数据集已显示出在蛋白质功能注释和宿主预测方面的增强能力。然而，这些研究仅关注了特定任务，没有考虑pLMs对各种宏基因组学任务普遍有益，从而错过了基础pLMs的真正潜力。pLMs本身的一个额外缺点是它们没有考虑进化驱动的基因组组织。最近的工作通过在短基因组片段上使pLM嵌入具有上下文性，甚至将整个基因组表示为pLM嵌入的聚合来解决这一问题。然而，这些模型每个只针对一种特定类型的表示：前者在增加了基因组上下文的情况下表示蛋白质，而后者将基因组表示为基于特定分类任务的蛋白质嵌入的加权和。因此，这些方法没有一种是真正可泛化到需要蛋白质和基因组水平推理的各种宏基因组学任务。

在这里，我们介绍我们的蛋白质集合变换器（PST），一种基于蛋白质的基因组语言模型，使用编码器-解码器范式同时产生基因组上下文化的蛋白质嵌入和基因组水平嵌入的单一端到端模型。我们在超过10万个高质量去重的病毒基因组上预训练了一个基础病毒PST（vPST）模型，这些基因组编码了超过600万蛋白质，并在一个独特的测试数据集上进行了评估，该数据集包含超过15万个高质量的病毒基因组，编码了超过700万蛋白质。我们证明vPST在基于共享蛋白质内容的病毒基因组-基因组关系方面表现更好。此外，我们观察到只有vPST能够一致地聚类操作相关蛋白质，如晚期基因蛋白，表明基因组上下文感知训练的重要性。此外，vPST蛋白质嵌入与蛋白质结构关系相关，通过聚类具有未注释功能的衣壳折叠蛋白与已注释衣壳蛋白得以证明。

值得注意的是，无论是基因组上下文化的vPST蛋白质嵌入还是基因组嵌入都未根据任何外部标签学习，这意味着它们将对广泛的应用程序有用。由于vPST的灵活性，我们建议vPST可以用于迁移学习来建模其他以病毒为中心的任务，如病毒基因和基因组识别、基因组质量控制、基因组装箱、分类和宿主预测，这些都是宏基因组学研究的主要组成部分。因此，我们预期vPST将是未来宏基因组学研究的基础。此外，我们认为，当在微生物基因组而非或除了病毒基因组上训练时，PST架构可以是微生物基因组学的通用模型。

### 结果

开发蛋白质集合变换器（PST）作为基因组语言模型  

![image](https://github.com/user-attachments/assets/4119dec1-65cf-443c-8153-b72389b68f43)  
图1. 蛋白质集合变换器（PST）的架构和训练体制。A）基于图的PST的总体概述，用于从上下文化的蛋白质嵌入中学习基因组表征。每个蛋白质由ESM2蛋白质嵌入表示。PST内部将每个基因组表示为一个图，由多个完全连接的局部相邻蛋白质的子图组成。每个子图的大小是一个调整的超参数。PST使用多头注意力来上下文化每个基因组内的蛋白质嵌入，并学习每个基因组的加权平均的每个蛋白质的权重。有关PST的建模中心视图，请参见扩展数据图1。蛋白质和基因组表征都可以用于适当的下游任务。B）包括数据增强技术C）PointSwap采样的三元组挖掘工作流。对于每个训练基因组，从定义为最小Chamfer距离的ESM2嵌入空间中识别出一个正基因组。然后，从PST嵌入空间中选择一个负基因组，该基因组是正基因组之后的下一个更远的基因组。我们通过在每个基因组及其正基因组之间交换相似的蛋白质向量来增强我们的训练数据。D）用于训练病毒PST（vPST）的三元组损失目标函数的图解表达。三元组损失的操作目标是使每个基因组及其正基因组在嵌入空间中比每个基因组及其负基因组更接近，距离边界可调。

PST（图1A，扩展数据图1）将基因组模型化为蛋白质集合，采用自然语言处理、集合和点集变换器领域的原则。因此，我们将PST称为基于蛋白质的基因组语言模型，因为它在基因组尺度上对蛋白质信息进行上下文化。在PST中，每个基因组的所有蛋白质都使用成熟的ESM2 pLM进行嵌入。与集合变换器不同，PST将小向量连接到pLM嵌入上，以模拟蛋白质基因组位置和编码链。每个基因组更新后的蛋白质嵌入被送入PST编码器，该编码器使用多头注意力来上下文化每个基因组内的蛋白质表征（简称为“PST蛋白质嵌入”）。这些PST蛋白质嵌入可用于蛋白质层面的任务，如蛋白质分类和功能注释。在端到端的PST中，PST蛋白质嵌入进一步传递给PST解码器，解码器也使用多头注意力来权衡基因组中每个蛋白质的相对重要性。这些权重用于加权平均上下文化的蛋白质，以产生基因组表征。

语言模型的常见训练目标之一是由类似的基于蛋白质的基因组语言模型使用的掩蔽语言建模，它涉及预测句子中掩蔽的标记（词）。在由表示为密集向量的蛋白质词组成的基因组句子的情况下，掩蔽语言建模的直观性较差，可能使训练过于复杂。我们选择镜像关系引导的基因组学，以更好地理解遗传多样性的模式，使用三元组损失函数（图1B, 1D）。在vPST基础模型的自我监督预训练期间，三元组损失使用vPST嵌入空间中的距离作为基因组-基因组相关性的衡量标准。在vPST中，基因组-基因组关系隐式地依赖于蛋白质-蛋白质的相关性。简而言之，三元组损失涉及形成基因组三元组，包括一个作为锚点，与锚点最相关的基因组作为正例，以及一个比正基因组不那么相似的基因组作为负例（图1B, 1D）。正例是在输入嵌入空间中的训练小批次内的基因组中使用Chamfer距离定义的，而负例则在vPST嵌入空间中采样。Chamfer距离计算为基因组对的蛋白质-蛋白质距离的平均最小值，意味着正基因组的蛋白质与锚点基因组最为相似。三元组损失的目标是将正基因组嵌入到比负基因组更接近锚点的位置，距离边界可调（图1D）。

为了帮助vPST学习更通用的表征，我们对每个基因组及其最相关的基因组使用数据增强技术PointSwap（图1C），这些基因组是根据上述Chamfer距离定义的（图1B）。每对基因组交换最相似的蛋白质向量，这类似于同源重组。然后我们更新三元组损失目标，包括最大化锚点基因组及其对应的通过PointSwap产生的增强混合基因组之间的相似性。  
![image](https://github.com/user-attachments/assets/34ac2c0c-226e-43af-8672-2a258bd1de82)  
图2. vPST学习了各种病毒集合的生物学意义深刻的基因组表征。A) 每种方法产生的基因组嵌入的UMAP降维图，按病毒领域进行颜色编码。“Kmer”代表4-mer核苷酸频率向量。“Ctx-avg”方法是每个基因组的vPST蛋白质嵌入的平均值。B-D) 通过在测试数据集的基因组嵌入的k-最近邻图上使用Leiden算法检测到的基因组聚类的统计数据：B) 聚集的基因组比例，C) 每个簇的平均基因组数量，D) 簇的总数。仅当一个簇至少有两个基因组时才计入统计。E) 上部：对簇内所有病毒对的氨基酸同一性（AAI）进行计算，并对整个簇进行平均。然后，根据每种方法，对每个簇的AAI进行加权平均，权重由簇的大小决定。下部：顶部行中的数据按照测试数据集中聚集的基因组比例进行缩放。所有分析均使用vPST测试数据集进行。  

为了定量评估每个基因组表征，我们从vPST测试数据集的每个基因组嵌入构建了一个相似性加权的k最近邻（kNN）图，并使用Leiden算法进行聚类。我们考虑了k（基因组邻居的数量）和聚类分辨率的一系列值，聚类分辨率设定了连接可以有多远的阈值，以更好地理解每个基因组表征的聚类趋势（图2B-D）。正如预期的那样，将k从2增加到50导致与至少1个其他基因组聚集的病毒比例增加（图2B），平均簇大小增加（图2C），总簇数减少（图2D）。同样，当k保持不变时，提高Leiden算法中的聚类分辨率会产生相反的效果，因为在kNN图中修剪了更远的连接（图2B-D，右列）。

接下来，我们计算了每个基因组簇中基因组对之间的平均氨基酸身份（AAI），并聚合所有基因组簇的AAI，以评估基因组簇的质量。正如预期的那样，基于蛋白质的方法导致基因组簇具有比基于核苷酸的方法更高的簇内AAI（图2E），这表明这些方法使用整体蛋白质相似性来理解病毒基因组关系。值得注意的是，pst-small基因组簇在所有方法中具有最高的AAI（图2E）。然而，当对高基因组单体率进行惩罚时，pst-large基因组簇具有最高的AAI（图2E）。重要的是，这意味着pst-large不仅基于蛋白质相似性聚集病毒基因组，还可以关联最大比例的基因组。此外，大多数方法在使用AAI特定于属或科级别聚集病毒时也优于基线（图2E，“AAI-”行）。此外，评估病毒及其宿主在基因组簇中的分类纯度并没有明显区分任何方法（扩展数据图4）。这可能表明，与基于AAI的评估相比，当前的病毒分类对于理解各种病毒集合中的病毒-病毒关系并不那么有信息性，AAI基于病毒基因组的更内在信息。此外，预测宿主的病毒比例较低（扩展数据图2D），这也可能影响此分析。

vPST检测到重要的病毒蛋白功能，包括识别新的潜在标志性蛋白

vPST基因组表征是根据输入蛋白嵌入的功能产生的，这些蛋白嵌入由中间PST编码器上下文化。因此，我们预期vPST的生物学意义深刻的基因组嵌入应该来自有意义的蛋白质表征。我们首先分析了pst-large中每个基因组的每个蛋白质的注意力得分，这些得分用作汇总vPST蛋白质嵌入以形成最终基因组表征的重要性得分。我们认为每个蛋白质的一般功能可能与高注意力相关。确实，结构蛋白（头部、包装、尾部）和复制或核苷酸代谢蛋白质通常是模型最关注的（图3A）。这是直观的，因为这些蛋白质对病毒至关重要，并且可能反映了它们在数据集中相对较大的丰度（扩展数据图5B）。此外，我们发现注意力得分与属于同一序列身份基础簇的蛋白质数量之间有微妙的关联（扩展数据图5A）。这反映了模型对更频繁看到的蛋白质赋予更高的权重。  

![image](https://github.com/user-attachments/assets/a061a8cb-88d0-4a7d-bcaf-e4213748701c)  
图3. vPST利用基因组上下文学习蛋白质功能关系。A) pst-large的缩放注意力，经过归一化以便在具有不同蛋白质数量的基因组间进行比较（参见方法部分），关于蛋白质功能的缩放注意力是每个前50个基于序列身份的蛋白质簇（mmseqs2）中所有蛋白质的最大缩放注意力。B) 两个基因组簇的UMAP降维图，这些基因组簇主要（≥85%的基因组）由Monodnaviria（顶部，13个基因组，80个蛋白质）或Duplodnaviria（底部，4个基因组，682个蛋白质）组成。颜色表示通过聚类所指蛋白质嵌入的k最近邻图并使用Leiden算法定义的蛋白质簇成员资格。这里，pst-large指的是vPST蛋白质嵌入。“IGR”指的是作为蛋白质簇功能纯度的度量，在这两个基因组簇中所有蛋白质簇的平均加权信息增益比（参见方法部分）。形状表示PHROG功能类别。C) 基于PHROG注释的功能共聚类摘要。每个连通分量在共现图中使用Leiden算法进行聚类，分辨率为1.0。边缘表示在相应蛋白质/ORF嵌入（列）的k最近邻图的聚类中，相对于注释配置文件的背景分布，功能类别对的富集程度更高。边缘的长度反映了富集程度，因为网络是使用弹簧力算法可视化的。虚线表示富集程度低于或等于预期，而实线表示富集程度高于预期。D) 对应于一个指定功能模块（列）的蛋白质簇的比例，使用VOG（顶部）或PHROG（底部）注释数据库。对于B和C，基因组使用pst-large基因组嵌入进行聚类（k=15，聚类分辨率=“高”）。每个基因组簇内的蛋白质使用k=15和聚类分辨率=“中”进行聚类。所有分析均使用vPST测试数据集生成。  

为了定量评估vPST理解蛋白质关系的能力，我们进行了与基因组簇类似的分析。使用Leiden算法在相似性加权的k最近邻（kNN）图上生成了基于嵌入的蛋白质簇。为了在聚类时减少潜在的噪声，我们限制了最近邻居的集合，仅包括同一基因组簇中的蛋白质，特别是使用最大化基因组簇内AAI的超参数（k=15，分辨率="高"，见图2E）。我们对蛋白质簇进行了类似的纯度分析，针对VOG和PHROG功能类别，并没有强烈指示哪种蛋白质或基因组聚类方法产生了最具功能纯度的基因组簇（扩展数据图6）。然而，使用ctx-avg-large嵌入聚类基因组往往在蛋白质簇功能纯度方面表现最佳（扩展数据图6B）。这一结果是有道理的，因为用于ctx-avg-large基因组嵌入的vPST蛋白质嵌入是vPST最后一次直接考虑蛋白质信息的时刻。此外，vPST蛋白质嵌入导致整体上最高的蛋白质功能纯度。

为了识别vPST胜过输入ESM2的情况，我们可视化了2个主要（≥85%的基因组）由Monodnaviria或Duplodnaviria组成的代表性基因组簇的蛋白质嵌入，使用大型嵌入（图3B）。在Monodnaviria簇中，有DNA结合蛋白，esm-large没有将这两种蛋白聚集在一起，反映了这两种蛋白的底层序列分化（35.5%的序列身份，覆盖约71%）。然而，pst-large将这些蛋白与复制启动蛋白聚集在一起，表明了广泛功能关系的检测。此外，esm-large嵌入将各种结构蛋白与这些DNA相互作用蛋白聚集在一起，而pst-large显著地将它们聚集成不同的簇。还有许多无法由PHROG（图3B）或VOG（扩展数据图5C）注释的蛋白质，无论使用哪种蛋白质嵌入，都与可注释蛋白质聚集在一起。对于Duplodnaviria簇也存在类似的视觉模式，这促使我们考虑这是否是vPST蛋白质聚类的一般现象。

vPST将相关蛋白质功能聚集到功能模块中

鉴于vPST利用基因组上下文，我们怀疑vPST能够识别反映底层基因组组织的相关蛋白质功能组。例如，在Lambda基因组中，晚期基因编码结构、包装和裂解蛋白是相邻的，并由单一启动子转录。因此，我们评估了蛋白质功能共聚类模式。对于每个蛋白质簇，我们计算了属于不同PHROG功能类别的蛋白质对共聚类的次数，与基于PHROG数据库类别的底层分布预期共聚类的每对类别的次数进行对比。结果显示的富集网络表明，两种vPST模型都能根据更广泛的功能模块对蛋白质进行分组（图3C），无论用于基因组聚类的是哪种基因组嵌入（扩展数据图7）。例如，尾部、头部和包装、连接器以及裂解蛋白，这些显著的晚期基因蛋白，始终在vPST蛋白质簇中高于背景共聚类。此外，与DNA相互作用（核苷酸代谢、溶原和基因表达）、早期基因（宿主接管、溶原）和溶原（溶原、溶原转化）功能模块在vPST蛋白质簇中富集。有趣的是，无论基因组如何聚类，使用ESM2蛋白质嵌入对蛋白质进行聚类都未能导致可解释的功能模块出现（图3C，扩展数据图7）。此外，尽管在GenSLM ORF簇中检测到了一些功能关系，但这并不一致，这取决于基因组的聚类方式。这些结果也与我们认为属于这些功能模块的蛋白质簇的比例一致，例如晚期基因、DNA相互作用、复制和包装（图3D）。值得注意的是，当使用VOG注释时，属于这些功能模块的蛋白质簇在vPST蛋白质簇中的比例大于ESM2或GenSLM簇，无论基因组如何聚类（扩展数据图8A）。这种效应在使用PHROG注释时不太明显（扩展数据图8B），但这种差异可能归因于PHROG数据库的功能注释总体减少（扩展数据图5B），导致排除了属于每个功能模块的更多蛋白质簇。这些数据表明，考虑基因组上下文更好地使vPST能够隐式地检测到编码在病毒基因组组织中的更广泛功能关联。

vPST扩展了我们对未知功能蛋白质的理解

有趣的是，无法由VOG或PHROG数据库注释的假设蛋白被pst-large视为最重要的（图3A）。一种解释是，由于未知功能的蛋白质占vPST测试数据集中所有蛋白质的70-90%（扩展数据图5B，补充表2），很可能存在在序列水平上发生分化的真正病毒标志性结构和复制蛋白。为了了解vPST是否使用超出序列级信息的信息来关联蛋白质，我们调查了与可检测的衣壳蛋白聚类的未注释蛋白质是否包含保存的类衣壳结构褶皱，作为这些未注释蛋白质确实是衣壳蛋白的证据。我们筛选了测试病毒中的蛋白质，以保留仅属于包含已注释衣壳蛋白或假设蛋白的蛋白质簇的蛋白质。然后我们使用foldseek

和ProstT5将这组蛋白质转化为结构字母，以便在蛋白质数据银行中搜索结构同源性。为了验证这种不直接推断蛋白质结构的方法的结构推理，我们独立地将参考HK97主要衣壳蛋白的结构与两个不同的AlphaFold 3预测的结构进行了比较，使用我们数据集中结构最相似的蛋白：一个由VOG配置文件检测到的未知功能蛋白（图4A，pTM=0.66）和一个完全未检测到的（图4B，pTM=0.6）。强烈的对齐表明，我们的工作流程可以准确地仅从蛋白质序列识别含衣壳褶皱的蛋白质。使用这种方法，vPST模型通常显示出未注释蛋白质与已知衣壳蛋白的结构同源性的最高平均比例（图4C），无论蛋白质或基因组如何聚类（扩展数据图9A）。GenSLM ORF嵌入在这项任务中也优于ESM2蛋白嵌入，可能是因为它在微生物基因组上进行了预训练，这可能包含了一些病毒序列，并在SARS-CoV-2基因组上进行了微调。  
![image](https://github.com/user-attachments/assets/f6a41e8b-0bb0-4093-9d64-9c70a2b36cca)  
图4. vPST扩展了假设蛋白的功能注释。AB) 与HK97主要衣壳蛋白（PDB: 2FS3, 灰色）的结构对齐，对于一个由VOG注释为未知的蛋白（A, “IMGVR_UViG_2851668853_000002|2851668853|2851668853|1181413-1220308_35”）以及另一个未被VOG检测到的蛋白（B, “IMGVR_UViG_3300036770_002539|3300036770|Ga0310126_0001736_19”）。红色卡通图是我们数据集中的查询蛋白，之所以选择这些蛋白是因为它们是每个类别中与HK97衣壳蛋白最相似的。C) 未被VOG注释的蛋白与有已知衣壳折叠结构同源性的已注释衣壳蛋白聚类的平均比例。结构同源性是通过使用foldseek对蛋白质数据银行数据库进行搜索来检测的。误差条表示用于基因组聚类的嵌入的标准偏差。值只能在每个子面板内进行比较。D) 从已注释蛋白到附近未注释蛋白的注释转移的敏感性，取决于用于基因组聚类的k最近邻的选择。如果最接近的蛋白（基于蛋白质/ORF嵌入的余弦距离）对每个未注释的蛋白具有VOG注释，则检测到注释转移的情况。所有分析均使用测试数据集中的基因组和蛋白进行。  

接下来，我们考虑利用嵌入空间的相似性将功能标签从已注释蛋白传递到未注释蛋白。为了评估vPST的注释传递能力，我们首先进行了最近邻敏感性分析。对于测试集中的所有未注释蛋白，我们使用每个蛋白质嵌入的余弦距离在每个基因组簇中识别最近的蛋白质。如果最近的蛋白质被VOG注释，我们认为这是注释改善的一个标志。基于蛋白质的嵌入在传递注释方面优于GenSLM ORF嵌入，无论基因组如何聚类（扩展数据图9B）。此外，当考虑更多基因组邻居时，这种注释改进的增加率显示了vPST的更高敏感性（图4D）。具体来说，使用ctx-avg-small或pst-large基因组嵌入聚类基因组导致随着允许更多基因组邻居的增加，改进率最大。有趣的是，当使用核苷酸方法进行基因组聚类或蛋白质距离搜索时，增加率下降，这表明增加更多基因组邻居阻碍了注释传递。这可能是由于核苷酸信息在捕捉远程关系方面的有限范围造成的。这意味着随着基于核苷酸的基因组簇大小的增加，未注释蛋白质在ORF嵌入空间中的最近邻就是另一个未注释蛋白质。此外，只考虑单个最近蛋白是一个保守的基线。通过考虑更多蛋白质邻居以及对vPST进行针对蛋白质注释任务的微调，不仅有可能改善这些结果。

### vPST可用于病毒宿主预测

![image](https://github.com/user-attachments/assets/97802159-6b68-4a86-bd45-10e5deb7c10c)  
图5. vPST改善宿主预测。A) CHERRY开发的用于宿主预测的图神经网络方法。节点表征被替换为相应的数据类型。B) 在指定置信度阈值以上预测其真实宿主物种的iPHoP测试病毒的比例。测试病毒未经过滤以排除与vPST训练集中病毒的相似性。图基模型是在本研究中训练的，而“iphop”代表iPHoP在测试集上的结果。  

鉴于我们期望vPST可以作为通用模型用于下游宏基因组学任务，我们使用pst-large基因组嵌入进行病毒宿主预测，以此作为概念验证（扩展数据图10A）。我们采用并修改了先前描述的图框架39，该框架将这一情景建模为病毒-宿主互动网络中的链接预测任务。简而言之，目标是预测任何病毒和宿主对是否应该存在链接，表示该宿主可能被相应病毒感染（图5A）。这个任务可以通过图神经网络（GNN）来执行，它使用一种卷积形式来聚合图中的局部（更相关的）部分以改善链接预测。

我们实现了基于GNN的CHERRY算法的一个变体39（图5A），将病毒和宿主的节点（基因组）嵌入替换为ESM2、vPST或CHERRY使用的四核苷酸频率（kmer）向量。尽管这种设计对于vPST来说可能不是最优的，因为vPST有针对病毒但不针对宿主的专门嵌入，但它能够直接比较基因组嵌入的选择，而不是各种病毒-宿主基因组嵌入组合。然后，我们使用宿主预测工具iPHoP40的训练数据集训练这些模型，以便与以前发布的工作进行比较（扩展数据图10A）。然后，每个训练好的模型和iPHoP都使用相同的iPHoP测试数据集进行评估。我们评估了是否可以高置信度识别每个测试病毒的真实宿主物种（图5B）。使用vPST基因组嵌入的模型在宿主物种级别上优于所有其他方法，尽管在保留≥0.9置信度的预测时，vPST和iPHoP之间的差距很小。尽管iPHoP测试集中有些病毒与vPST训练集中的病毒相似（扩展数据图10B），排除这些病毒并不改变整体结果（扩展数据图10D）。此外，在更广泛的宿主分类水平上评估时，kmer模型表现最好，CHERRY和vPST紧随其后（扩展数据图10D）。kmer模型显著包括对CHERRY进行的特定于实现的更改，这似乎提高了性能。此外，vPST在更广泛的宿主分类水平上的较低性能可以由vPST基因组嵌入未针对宿主调整这一事实来解释。然而，与vPST更为可比的基于ESM2的模型在任何置信度阈值或宿主分类级别上的表现都不佳。这直接展示了在宏基因组学任务中使用病毒数据集进行训练的重要性。 

### 讨论

在这里，我们介绍了PST框架，用于将基因组建模为蛋白质集合，其中每个蛋白质最初由信息丰富的ESM2蛋白质嵌入表示。PST上下文化输入的蛋白质嵌入，并随后生成基因组表征作为上下文化蛋白质嵌入的加权平均，这可以针对蛋白质层面或基因组层面的下游任务。在一个大型、多样化的病毒基因组数据集上预训练时，vPST在理解病毒基因组间关系方面显示出优越的能力（图2E）。在蛋白质层面，vPST蛋白质嵌入展示了广泛功能分组的模式，一致地将晚期基因蛋白聚集在一起（图3B）。此外，vPST经常将不能被VOG注释的含衣壳褶皱蛋白与已注释的衣壳蛋白聚集在一起（图4A），表明vPST使用推断的结构信息来关联蛋白质。vPST还显示出高灵敏度的注释传递（图4B）。这些蛋白质层面任务的表现可以通过用病毒序列微调ESM2 pLM和训练一个更直接考虑蛋白质-蛋白质和基因组-基因组关系的双重目标vPST来进一步提高。最后，当应用于病毒宿主预测任务时，vPST基因组嵌入能够在与两个先前发布的宿主预测工具比较时，检测出最多的病毒的真实宿主物种（图5B）。值得注意的是，我们故意没有过度分析概念验证宿主预测任务中的细微表现差异，因为还有许多超出我们工作范围的训练技术可能导致了更优越的基于vPST的宿主预测模型。因此，重要的是要强调，基于vPST的宿主预测模型的表现与现有的宿主预测工具相当（有时甚至更好），而vPST最初并未被指定进行宿主预测，也没有经过大量的训练时间。
![image](https://github.com/user-attachments/assets/9f49e2af-26b1-48aa-a59b-557ca1486db1)  
图6. PST可以是一个通用的微生物和病毒基因组语言模型。A) 预训练的vPST的潜在下游任务，代表了典型计算宏基因组学流程中常见的所需步骤。B) 基于PST的基因组语言模型的示例工作流程，可以结合微生物和病毒输入基因组数据集。  

重申，尽管没有针对这些目标训练vPST，它在多种宏基因组学任务中的卓越表现仍然显现出来。总的来说，我们的结果表明vPST适合作为常见宏基因组学任务的基础模型，如病毒识别、分类、宿主预测、蛋白质注释、基因组分装等（图6A）。我们预期，对下游宏基因组学问题进行更深入的研究将从我们预训练的vPST开始受益。此外，对vPST的微调可以为这些下游任务带来更大的性能提升。例如，使用病毒-宿主数据集对端到端宿主预测模型进行微调，可能会显著提高预测能力，相比我们观察到的结果。此外，iPHoP训练数据集的多样性有限（扩展数据图10C），这可能表明这里的结果并不代表真实性能。然而，我们的工作提供了一个独立的基于vPST的宿主预测工具的指南。

生物基础模型由于可能的生物安全威胁（如生成新的病原病毒或指导功能增益的病毒变异）而越来越受到关注。例如，AlphaFold 3网络服务器不允许对某些病毒蛋白进行预测，Evo排除了具有真核宿主的病毒的预训练数据，ESM3-open过滤了其训练集中的病毒序列和选定代理。在开发vPST时，我们评估了这种病毒基础模型的伦理影响，并在发布vPST代码和模型权重之前让独立专家考虑这些影响。然而，我们认为vPST的生物安全风险较低。首先，vPST训练病毒中只有0.2%感染人类。其中，只有4种在CDC的生物恐怖主义剂列表上，10种更多的由国家呼吸和肠道病毒监测系统监控。此外，只有1%的训练病毒感染哺乳动物，这将是最可能溢出到人类的病毒库。由于我们的模型未考虑宿主身份，这些病毒在训练数据集中的低丰度可能最大限度地减少了它们对学习的vPST嵌入的影响。其次，vPST的最低分辨率是在蛋白质水平上，这意味着使用vPST反向工程一个全新的病毒基因组将是困难的。虽然一种核苷酸语言模型报告了生成全新细菌病毒基因组的能力，但没有调查这些基因组与训练数据集的相似性。一个陷阱是模型可能只是生成与训练数据没有太大差异的新颖基因组。从我们基于蛋白质的工作中逆向工程基因组由于人类病毒倾向于编码和表达基因的复杂性（重叠、备选起始、备选剪接、翻译后处理等）而更加复杂。这些分子生物学问题可能意味着实现生成的病毒基因组的体内活性将是具有挑战性的。因此，我们认为，我们的工作展示的和未来潜在的益处（图6A）超过了任何需要大量资源才能释放的假设威胁。

最后，虽然我们的PST架构在这项研究中训练于病毒蛋白和基因组，但它对蛋白质的来源和基因组的类型是不敏感的。我们框架的唯一要求是有序的蛋白质序列和每个ORF的基因组链。这些要求更容易由微生物基因组满足，其中计算ORF调用既准确又常见。然而，理论上我们的PST也可以用足够大的实验确定的真核生物ORF数据集工作。尽管如此，我们提出，我们的PST实现同样适合开发一个微生物基础模型，以解决微生物基因组学中的挑战（图6B），这显著地还包括蛋白质注释率低和高序列分化的问题。事实上，我们的基础vPST模型对于宿主基因组表征在病毒-宿主预测任务中仍然有用，尽管只在病毒上进行了训练。  

### 数据可用性

公开可用的病毒基因组来源列在补充表1中。与本文稿特定相关的补充数据，包括蛋白质FASTA文件、蛋白质和基因组嵌入、训练好的vPST模型权重以及病毒-宿主互动图，已存放在DRYAD：(doi: 10.5061/dryad.d7wm37q8w)。该资源库将在完成我们的生物安全审查后公开。

### 代码可用性

与本文稿特定相关的PST模型架构和分析的所有代码将在以下位置发布：https://github.com/AnantharamanLab/protein_set_transformer。特别是为了与文稿相关的分析，每个使用代码的方法部分都将提供Jupyter笔记本。我们还将提供额外的资源库，用于生成ESM2蛋白质嵌入、GenSLM ORF和基因组嵌入以及HyenaDNA基因组嵌入，这些可以在上面提到的主模型资源库中找到。这些资源库将在完成我们的生物安全审查后公开。

## Online Methods

### Viral genome datasets
我们从12个不同的公开可用来源获取了病毒基因组作为训练数据集。对于GTDB（r202），我们使用了PhageBoost（v0.1.7）的默认设置来识别整合的噬菌体，过滤掉那些至少没有编码20个蛋白的预测。然后，我们过滤掉了那些未被CheckV（v1.0.1）认为是完整或高质量的基因组。接着，我们使用自定义工作流去重这些基因组。我们首先使用skani（v0.1.0 sketch: --fast）计算所有病毒对之间的平均核苷酸身份（ANI）。我们构建了一个图，图中的边将ANI≥95%且两个基因组的对齐覆盖率≥50%的病毒连接起来。边的权重是ANI和覆盖率的乘积。然后，我们使用马尔可夫聚类算法（mcl v14-137 -I 2.0）对这个图进行聚类，随机选取每个簇中的一个基因组作为代表基因组。对于测试数据集，我们选择了IMG/VR v411中每个病毒操作分类单元中最完整、最少污染和最长的基因组，确保每个代表基因组都被CheckV认为是高质量的。然后，我们使用与上述类似的方法，使用skani（--slow，≥95% ANI，≥85% 覆盖率）和mcl将这一假设的测试数据集与训练数据集去重。我们保留了所有没有与训练病毒聚集在一起的病毒。对于这两个数据集，我们过滤掉了那些预测只编码1个蛋白的病毒。最终，训练数据集的病毒基因组数量为103,589，测试数据集为151,255。

对于所有病毒，我们使用prodigal的Python绑定pyrodigal（v2.3.0）为单个连续体病毒预测蛋白质开放阅读框（ORFs），并使用prodigal-gv（v2.11.0）为病毒宏基因组组装基因组（vMAGs）预测。我们没有考虑由prodigal-gv（包括巨型病毒和使用替代遗传密码的病毒的基因模型）做出的更新对整个数据集的影响足够大，因为数据的规模和分布。这导致训练数据集有6,391,562个蛋白质，测试数据集有7,182,220个蛋白质。

对于训练病毒，IMG/VR v3未提供的病毒分类使用geNomad（v1.5.0）分配，以获得与当前标准一致的标签。对于测试病毒，我们使用了提供的分类标签，因为它们与当前标准一致，大多数也是使用geNomad预测的。我们没有对这些病毒进行宿主预测，因此宿主标签要么由源数据库预测，要么由于整合性噬菌体预测而已知。训练和测试病毒的信息摘要可以在补充表1中找到。

### ESM2 protein language model embeddings 
PyTorch (v2.1.0) 和 fair-esm3 (v2.0.0) 被用于获取蛋白质嵌入。我们将 ESM2 模型 "esm2_t6_8M_UR50D"（6 层，800 万参数，320 维嵌入）和 "esm2_t30_150M_UR50D"（30 层，1.5 亿参数，640 维嵌入）分别称为 "esm-small" 和 "esm-large"。每个蛋白质的氨基酸嵌入被平均为一个单一的向量。对于长度超过 20,000 个氨基酸的蛋白质，序列会被分成两半，每一半的嵌入会被平均，形成最终的嵌入。这仅影响了宿主预测分析中的一个细菌蛋白质。

### The Protein Set Transformer model architecture

![image](https://github.com/user-attachments/assets/39de4a15-1a34-4b9b-93ba-51b1f631bfd1)  

PST使用先前描述的编码器-解码器范式与SetTransformer。编码器使用多头自注意力将每个蛋白质上下文化为同一基因组内的其他蛋白质。然后，解码器使用多头注意力池化将基因组总结为上下文化蛋白质嵌入的加权平均。为了在每个基因组中上下文化蛋白质，我们在PST编码器的每层中使用基于图的多头缩放点积自注意力实现。  
![image](https://github.com/user-attachments/assets/71bcf8f9-ade4-46ec-8bd6-1376d29da464)  

其中 Xi(l上标)是第三层编码器中第l个蛋白质的嵌入向量，d是蛋白质嵌入维度。同样， W（·,l） 是第三层编码器中查询、键和值的权重矩阵。d是第i个蛋白质在同一基因组子图中的蛋白质邻居集合。Α（ij） 是缩放点积注意力计算。GraphSoftmax 是一个修改过的softmax函数，只在属于同一基因组的子图集合内规范化注意力值。因此，只有在同一子图中的蛋白质相互关注，但注意力值是通过基因组中的所有蛋白质规范化的。为了实现多头注意力，我们将输入蛋白质嵌入按照注意力头的数量和嵌入维度的相同数量分割。在自注意力计算之后，我们将每个头的输出重新连接起来。此外，我们采用了预规范化策略，在线性层之前规范化输入蛋白质嵌入。具体来说，我们使用了PyTorch-Geometric中实现的GraphNorm规范化操作符，只在每个基因组内规范化蛋白质嵌入。此外，我们使用了相应的跳过连接，在其中未转换的输入被添加到注意力后的值中。因此，完整的PST编码器层可以用以下一组方程数学表示：
![image](https://github.com/user-attachments/assets/95ee7319-5082-4b52-bf8a-926db981120a)  
其中 代表中间蛋白质表征， 是输入的蛋白质嵌入，位于堆叠的批次中。FF代表一个具有GELU（高斯误差线性单元）激活功能和每层后的dropout的两层前馈网络。在完整的PST编码器之后，进行了最终的GraphNorm操作。

PST解码器使用多头注意力来计算每个蛋白质的注意力得分，这些得分将用作每个基因组上蛋白质嵌入的加权平均的权重。如先前描述，多头注意力池化使用一个可学习的维度种子向量作为在计算注意力时的查询。在注意力计算期间，从PST编码器输出的上下文化蛋白质嵌入被投射到S：
![image](https://github.com/user-attachments/assets/93d62956-24bf-42b2-a3e2-3e91e0f29b70)  

之后对进行重新加权，然后对每个基因组的进行平均，以产生最终的基因组输出。PST解码器的完整方程组与编码器的方程（方程1）类似：  

![image](https://github.com/user-attachments/assets/3989e9bd-105f-42ee-b3f9-0317575c6b63)  
其中 是线性层的权重。GraphPool是一个池化（平均）操作符，用于每个基因组图，它平均每个基因组的上下文化加权蛋白质嵌入。每个FF都是一个不同的具有GELU激活功能和每层后的dropout的两层前馈网络。 是最终的基因组嵌入。详见扩展数据图1，用于显示PST架构的图解表示。  
### Training the viral Protein Set Transformer foundation model with triplet loss
基础病毒蛋白质集合变换器（vPST）模型是使用之前描述的自监督三元损失目标进行训练的：  

![image](https://github.com/user-attachments/assets/6c0eaf07-7f16-400f-bb33-0cd5aba27537)  


其中 􀀀 是作为锚点的第个基因组，􀀀 是第个基因组的正基因组，􀀀 是第个基因组的负基因组，􀀀 是使用PointSwap采样方法创建的第个基因组的增强基因组。D· 是由完整的PST神经网络模拟的函数，C!EMC 是向量 ! 和 M 之间的L2（欧几里得）距离。I􀀀 749 是类权重，用来放大其他类别中较少的类别对损失的贡献。我们使用每个病毒的病毒领域作为类别，并将 I􀀀 751 计算为逆频率。假设第个基因组属于病毒领域N，那么类权重计算如下：

![image](https://github.com/user-attachments/assets/56db9865-0bed-40a3-a1b5-047ddc5a746e)  

![image](https://github.com/user-attachments/assets/b9ef10df-fb42-4f71-9d41-6ff83a55670c)  
负样本挖掘发生在PST嵌入空间中，并且需要正基因组进行半硬采样情境。选择负基因组的唯一候选者是那些在PST嵌入空间中使用欧几里得距离比正基因组更远的基因组，我们选择第一个比正基因组更远的基因组作为半硬情况下的负基因组。在没有比正基因组更远的基因组的情况下，比如在训练初期当模型权重还没有很好优化的时候，我们放宽半硬采样要求，选择最接近正基因组的基因组作为负基因组。由于负样本挖掘是自监督的，我们使用指数衰减重新加权因子 F􀀀 来降低负基因组的差选择的权重，这些选择实际上与锚点基因组非常相似。值得注意的是，F􀀀 重新加权因子取决于Chamfer距离（方程2）和随后的输入ESM2嵌入。因此，我们在挖掘正负基因组时隐式地将ESM2嵌入视为蛋白质表征的真实基准。

### PointSwap sampling

![image](https://github.com/user-attachments/assets/b3fb891b-3c93-4807-b27d-04a19f574277)  
![image](https://github.com/user-attachments/assets/87a698b1-0f4d-42b6-87cd-e180915f4d9d)  

### Modified Leave-One-Group-Out cross validation and hyperparameter tuning

为了优化模型超参数（补充表3），我们使用Optuna（v3.3.0）通过贝叶斯树结构Parzen估计方法迭代采样超参数，以优化目标函数。模型性能使用修改版的留一组外（LOGO）交叉验证（CV）策略进行评估。这里，我们将病毒分类领域视为一个组，共5个组：Duplodnaviria、Monodnaviria、Riboviria、Varidnaviria以及未知/其他。我们修改了LOGO策略，始终在每个训练折叠中包括Duplodnaviria，因为这一组病毒占训练数据集的65.4%。这导致训练了4个单独的模型，在其余病毒领域上进行验证。四个折叠在训练过程中同步进行，以便能够实时监控每个调整试验的性能，作为每个折叠平均性能的监控。因此，我们可以根据每个折叠的平均验证损失的几个标准早期停止试验：（1）如果在经过3个周期后损失平台化（变化的标准差小于1e-6），（2）如果损失在5个周期内没有下降0.05，（3）如果当前性能比同一训练周期内之前试验的中位性能差，（4）如果模型已经训练了20个周期，（5）如果已经过去了24小时，（6）如果损失不是有限的。对于编号3，这是由Optuna框架维护的，并且我们要求至少完成1次完整的试验才能启用这一功能。在由于原因1、2、3和6的情况下提前停止的试验，这些试验被标记为剪枝，并且不被Optuna的中位性能计算使用。

总共，我们使用“esm-large”蛋白质嵌入作为输入训练了16个完整的、16个失败的和22个剪枝的试验，使用“esm-small”蛋白质嵌入作为输入训练了45个完整的、1个失败的和29个剪枝的试验。唯一的失败原因是由于在威斯康星大学麦迪逊分校高通量计算中心托管的A100 80GB vRAM GPUs上发生的内存溢出错误。所有试验都使用1个GPU进行调整，因为Optuna对GPU并行支持有限。

每次训练迭代的最终性能是4个模型的平均验证损失。一旦最佳模型设置的三元损失降至20.0以下，我们选择了最佳超参数配置，并训练了2个vPST模型，分别对应于esm-small和esm-large蛋白质嵌入，我们称之为pst-small和pst-large。每个vPST模型都在不进行验证的情况下在所有基因组上训练了15（pst-large, 33.7小时）或50个周期（pst-small, 10.2小时）。一旦训练损失平台化且在5个周期内没有下降0.05，训练就停止了。在训练最终模型期间，使用了一个学习率调度器，该调度器使每个周期的学习率线性下降，pst-large或100（pst-small）小批量累积后进行反向传递。我们测试了1、25、50、100和250的批量累积大小，上述值导致了最佳模型。

无论是调整还是训练最终模型，都将梯度裁剪以保持所有值低于1.0的幅度，并使用bfloat-16数据进行混合精度训练，当可用时。这些选择有助于稳定训练。我们的折叠训练同步策略和修改的LOGO CV方法在名为“lightning-cv”的自定义包中实现，该包可从主模型存储库获取。这个包大量依赖并扩展了PyTorch-Lightning（v2.0.7）中的lightning-fabric子库的功能。

训练停止于一旦训练损失达到平台且在5个周期内没有下降0.05。在训练最终模型期间，使用了一个每个周期线性减小学习率的调度器，且在反向传递之前累积了50（pst-large）或100（pst-small）的小批量。我们测试了1、25、50、100和250的批量累积大小，上述值产生了最佳模型。

在调整和训练最终模型期间，梯度被裁剪以保持所有值低于1.0的幅度，并且我们使用了混合精度训练，当可用时使用bfloat-16数据。这些选择有助于稳定训练。我们的折叠训练同步策略和修改的LOGO CV方法在一个名为“lightning-cv”的自定义包中实现，该包可从主模型仓库获得。这个包大量依赖并扩展了PyTorch-Lightning（v2.0.7）中的lightning-fabric子库的功能。

### GenSLM open reading frame (ORF) and genome embeddings
我们使用了GenSLM 25M参数模型（“genslm_25M_patric”，2023年9月下载）进行分析，因为输出的嵌入维度（512）与使用的其他蛋白质和基因组嵌入相当。GenSLM基础模型仅在细菌和古菌核苷酸基因上进行预训练，其中基因序列被拆分为密码子作为输入。然后，作者在SARS-CoV-2基因组的数据集上对基础模型进行了微调。但是，尚不清楚是否只包括SARS-CoV-2的开放阅读框架（ORFs），或者在微调期间使用了整个病毒基因组作为输入。这一问题进一步复杂化了，因为SARS-CoV-2基因组的蛋白质编码密度为71.2%（基于NCBI RefSeq参考序列NC_045512.2）。我们选择模仿预训练设置，并为我们数据集中的每个病毒输入蛋白质编码的ORFs。值得注意的是，我们使用GenSLM作为ESM2的核苷酸类比，产生类似于ESM2蛋白质嵌入的ORF嵌入。我们使用这些ORF嵌入进行蛋白质/ORF分析，并将这些在每个基因组上的平均值作为基因组嵌入进行基因组分析。

### HyenaDNA genome embeddings
我们使用HyenaDNA模型，其上下文大小最长（1M核苷酸，“large-1m”，2023年11月从HuggingFace下载），具有6.5M参数。我们将所有非ACGTN核苷酸转换为N。大于1M核苷酸的基因组被分割成最多1M核苷酸的不重叠片段。然后，每个片段被标记化并输入到“large-1m”HyenaDNA模型中。每个基因组片段的嵌入被平均以产生最终的基因组嵌入。我们还对碎片化的基因组（即vMAGs）使用了同样的平均方法，其中最终的基因组嵌入是每个片段的平均值。

### Tetranucleotide frequency vectors as simple genome embeddings

![image](https://github.com/user-attachments/assets/76ebb41d-69f2-4615-9ebb-9284d798c500)  
 

### Clustering genome and protein embeddings

![image](https://github.com/user-attachments/assets/36b4948f-8d47-48d3-9d48-4dd03093f109)  
 

### Genome and protein clustering evaluation
为了比较使用不同输入嵌入形成的簇，我们计算了每个簇的基因组之间、病毒与宿主的分类纯度以及蛋白质功能纯度的簇间平均氨基酸身份（AAI）。这些簇级指标是根据每个簇的大小加权的，特别是在大小计算中包括了未标记的基因组或蛋白质，然后用加权平均来总结：

![image](https://github.com/user-attachments/assets/db10ad9b-87e8-4d23-9d56-3c961b2083f4)  
蛋白质功能纯度是使用VOG或PHROG中整理的功能分类计算的。为了计算聚类的纯度（病毒或宿主分类、蛋白质功能），我们使用信息增益比作为纯度的代理。对于分类纯度，我们考虑了将所有基因组聚类成一个单一簇的情况作为背景。对于功能纯度，我们使用注释数据库中的功能分类分布作为背景。在任一情况下，未标记的蛋白质和基因组在熵计算期间被排除，但在簇大小加权时包括在内。然后我们按如下方式计算信息增益比：  
![image](https://github.com/user-attachments/assets/3508f574-487f-46d4-af3b-3334ad77a67e)  
### Average amino acid identity (AAI) 

我们使用mmseqs2（v13.45111）和polars（v0.20.6）来大规模计算病毒对之间的氨基酸身份（AAI）。考虑到本研究中病毒的大量数量（>250k），我们没有对所有病毒对（约32.5亿）进行详尽的AAI计算。相反，我们使用mmseqs2实现的启发式方法，只考虑在使用mmseqs2搜索设置时能够检测到任何蛋白质相似性的病毒之间的AAI：-s 7.5 -c 0.3 -e 1e-3。对于每对病毒基因组，我们只保留了每个基因组中每个蛋白质的最佳命中结果。然后，通过mmseqs2计算得到的蛋白质-蛋白质序列相似性的平均值来计算AAI。  

### Average amino acid identity (AAI) genome clustering
![image](https://github.com/user-attachments/assets/221cc6db-e5a3-47e7-a588-465e3363cf28)  
### Protein functional annotation
我们使用VOG (r219) 和 PHROG58 (v4) 数据库对病毒蛋白进行注释。对于VOG，它提供了配置文件隐藏马尔可夫模型（HMMs），我们使用pyhmmer (v0.9.0) 并设置一个比特分数截止值为40。对于PHROG，我们使用mmseqs2 (v13.45111) 并采用推荐的搜索设置（https://phrogs.lmge.uca.fr/READMORE.php）。在两种情况下，我们保留了每个蛋白质的最佳命中，以最高比特分数为准。对于每个数据库，我们整理了我们下面描述的每个注释的功能类别。

对于已经提供10个类别（包括未知功能）的PHROG，我们手动调整了某些类别。我们对PHROG数据库的手动整理影响了38,880个配置文件中的1,937个。我们重新命名了以下类别以更直观地理解功能类别：“DNA, RNA 和核苷酸代谢”改为“核苷酸代谢”、“整合和切除”改为“溶原性”、和“转录调控”改为“基因表达”。然后我们解散了“moron, auxiliary metabolic gene and host takeover”类别，因为它太宽泛且相对无关。这461个配置文件被分割到已经存在的“其他”类别中；新创建的“host takeover”、“lysogenic conversion”、“metabolic gene”；以及重命名的“gene expression”、“lysogeny”和“nucleotide metabolism”类别。像“membrane associated protein”和“ABC transporter”这样的通用注释被放在“其他”类别中。我们认为涉及宿主复制和细胞分裂抑制、超感染排除、抗西格玛因子和抗宿主抗病毒蛋白的蛋白质属于“host takeover”。编码毒素或抗毒素/抗性蛋白的蛋白质被分类为“溶原性转化”。直接参与特定代谢转化的蛋白质被放在“metabolic gene”中，而像“nicotinamide mononucleotide transporter”这样的辅助或通用蛋白质被认为是“其他”。这些更改可以在补充表5中找到。

VOG提供非常广泛的类别：“Xr”用于复制，“Xs”用于结构，“Xh”用于有利于宿主，“Xp”用于有利于病毒，以及“Xu”用于假设蛋白质。“Xh”和“Xp”类别在蛋白质可能执行的具体功能上也不明确。因此，我们使用特定HMM注释描述上的文本模式匹配来将所有HMM划分为9个类别：抗宿主防御、出口、基因表达、整合、包装、复制、结构、其他和未知。简要地，我们将终止酶、门蛋白和头部包装蛋白从其他结构蛋白中分离出来，归为“包装”类别。裂解、病毒输出和芽生HMM被统一视为“出口”组。“整合”包括整合酶和切除酶以及转座酶。我们认为所有核苷酸代谢和基因组复制都属于“复制”。为了考虑文本匹配中的重叠，我们执行了以下层次结构：结构 > 包装 > 出口 > 整合 > 基因表达 > 抗宿主防御 > 复制 > 未知 > “RNA聚合酶” > 其他。因此，每个HMM的最终类别是层次结构中最高的。我们添加了RNA聚合酶，这些聚合酶没有指明它们是复制的RNA导向还是转录的DNA导向，在底部将这些特定的RNA聚合酶放在“基因表达”类别中。此外，没有匹配项的HMM因此被考虑在“其他”类别中。每个VOG r219 HMM的类别可以在补充表6中找到，用于分类每个HMM的正则表达式模式可以在补充表7中找到。  
### Protein attention scaling and analysis
![image](https://github.com/user-attachments/assets/f5796fb4-deb0-44c8-8e4f-7bfe6f50f38a)  
![image](https://github.com/user-attachments/assets/af451230-b54a-4259-a036-e6227ce4bc8d)  
### Protein annotation improvement
![image](https://github.com/user-attachments/assets/75a1528d-fa08-4598-ae4e-6527e129263f)  
### Protein function co-clustering
![image](https://github.com/user-attachments/assets/ba9bfdd1-a548-412f-bb71-858f5b6ff31f)  
### Protein functional module detection
我们基于整理的功能分类（补充表5和6）和注释文本搜索，定义了以下蛋白质功能模块。对于PHROG数据库中的复制蛋白，我们包括最初被归类为“核苷酸代谢”的蛋白质，并且与以下正则表达式模式匹配：“(?i)DNA pol|single strand DNA binding|Par[AB]|DNA primase|(DNA)?[ ]?helicase|repl|primosom|terminal|ribonucleo[st]ide(.*)?reductase|NDP reductase”。对于VOG，我们考虑了复制类别中的所有命中。对于PHROG的包装模块，我们包括了属于“头部和包装”类别的命中，并且特别匹配了正则表达式“(?i)terminase|portal”。对于VOG，我们只考虑了“包装”类别中的内容。对于PHROG的DNA相互作用模块，我们包括了属于“核苷酸代谢”、“溶原性”或“基因表达”类别的所有命中。对于VOG，所有属于“复制”、“整合”、“包装”和“基因表达”的命中都被包括。对于PHROG的晚期基因，保留了“尾部”、“头部和包装”、“连接器”和“裂解”的类别中的注释。同样地，对于VOG，“结构”、“出口”和“包装”的类别也被包括。  
我们认为蛋白质簇符合特定功能模块的要求，如果它们满足以下模块特定的标准：对于只考虑单一功能类别（复制、包装）的搜索，我们要求该类别中至少有2种不同注释的蛋白质。由于数据量庞大，我们无法确保这两种不同的注释指的是真正不同的蛋白质功能，而不仅仅是同一功能用不同的措辞表达。对于多类别搜索（晚期基因、DNA相互作用），我们要求至少有2个类别被代表。在任何情况下，我们排除了在指定功能类别之外有任何注释蛋白质的蛋白质簇，以专注于最符合我们对功能模块定义的蛋白质簇。  
### Capsid structure searches
为了量化基于嵌入的蛋白质簇共簇VOG可检测的衣壳蛋白（VOG比特分数≥75）与无法由VOG分配功能的蛋白质的频率，我们排除了所有不仅由注释的衣壳和假设性蛋白质组成的基于嵌入的蛋白质簇。然后，我们筛选了这些候选蛋白质集，保留那些在所有聚类配置中至少10次符合前述标准的蛋白质。我们还包括了基于序列身份的簇（mmseqs2 v13.45111 cluster -s 7.5 -c 0.5），这些簇也由未注释和衣壳蛋白组成，作为正对照。这导致了共100,704个蛋白质用于此分析。

我们使用foldseek34 (v9.427df8a) 将我们的蛋白质序列数据库转换为使用ProstT535模型（2024年7月下载；foldseek createdb时选用“—prostt5-model”选项）的3Di-结构数据库，该模型使用语言标记表示结构特征。我们使用默认设置将我们的3Di-结构数据库与蛋白质数据银行36（PDB；2024年7月使用foldseek下载）的295k结构进行了搜索。我们排除了所有比特分数低于100的对齐，并手动将PDB结构注释为病毒衣壳，使用以下查询在PDB网站（https://www.rcsb.org）进行搜索：“capsid, major capsid, coat, minor capsid, virion”。我们通过使用TM-align59（在PDB网站实现）将AlphaFold 3模型（https://alphafoldserver.com）的单体结构与HK97主要衣壳蛋白（2FS3）进行对齐来验证这种方法。我们选择2个蛋白质，每个来自VOG未知功能的配置文件注释的蛋白质或VOG未检测到的蛋白质，这些蛋白质具有由foldseek确定的最高得分的结构对齐，用于此分析。

然后，我们计算每个簇中具有与PDB衣壳蛋白结构对齐的未注释蛋白质的比例。为了总结每种聚类超参数、基因组嵌入和蛋白质嵌入组合的这些比例，我们计算了这些比例的加权平均值，使用簇大小作为权重。  
### Embedding UMAP visualization
我们使用了UMAP算法的Python实现（umap-learn v0.5.3）仅用于嵌入的可视化。对于基因组嵌入，我们使用由欧几里得距离定义的15个最近邻。在计算降维嵌入时，我们将训练和测试数据集的每种类型的基因组嵌入共同嵌入到同一空间中。对于蛋白质嵌入，我们首先将每个蛋白质嵌入进行单位规范化，使其L2-范数为1。然后，我们使用由余弦距离定义的8个最近邻，因为这个值提供了最佳的视觉分离。在这两种情况下，我们在可视化前没有减少维度，所以嵌入本身直接用作UMAP算法的输入。  
### Graph-based host prediction framework
![image](https://github.com/user-attachments/assets/45eeb49e-0c7f-41f7-b43b-5d46f4dd12d3)  
![image](https://github.com/user-attachments/assets/cfd0ac39-d452-432f-a553-66015485e745)  

### Host prediction training and test datasets 

对于病毒宿主预测的概念验证，我们的框架是基于CHERRY39，它在病毒-宿主互动网络上应用图学习。为了构建已知病毒-宿主对的网络，我们使用了iPHoP40的训练和测试数据集。具体来说，训练数据集包括了2021年之前NCBI RefSeq中的3628个完整的细菌和古菌病毒。iPHoP的测试数据集由NCBI GenBank中与训练数据集不同的1636个完整的细菌和古菌病毒组成。尽管这两个数据集都指明了宿主的分类，但它们没有提供连接病毒所需的特定基因组访问权限，这是构建互动网络所必需的。

对于训练数据集，我们使用了病毒-宿主数据库62（2024年4月访问）来确定完整的宿主分类。然后，我们选择了与宿主分类相关的NCBI RefSeq代表序列（如果存在的话），或者从NCBI GenBank（2024年5月访问）选择最完整的（最长且组装水平为“完整基因组”）基因组。如果存在多个宿主，如病毒宿主范围相对较广的情况，我们包括了病毒-宿主数据库中的所有宿主。宿主集明显包括同一物种的多个菌株或病毒-宿主数据库中指明的同属的物种。然后，任何菌株信息都被忽略，因此评估的最低水平是在宿主物种层面上。

我们使用iPHoP40补充表2中提供的信息对测试数据集进行了类似的搜索。我们将测试病毒宿主的物种等级未知的（例如“Wolbachia sp.”）分为两个不同的集合。如果这些宿主已经在训练数据集的宿主集中，我们就不会检索任何新的宿主基因组。相反，我们考虑所有当前在与这些病毒同属的宿主集中的宿主作为这些病毒的潜在宿主。对于新宿主，我们使用了与上述相同的搜索标准为这些病毒添加一个新的宿主。这导致了总共805个宿主基因组，对应于594个独特的宿主物种。  
### Constructing the virus-host interaction network
为了构建病毒-宿主相互作用网络，我们构建了一个异质图，该图具有两种节点类型（病毒、宿主）和两种边类型（病毒相关-到-病毒，病毒感染-宿主）。对于病毒-宿主的边，我们包括了上面识别的所有病毒-宿主对，这意味着图中包含了训练和测试病毒。我们显著地偏离了CHERRY的实现，排除了通过BLASTn基因组比对（前病毒）或CRISPR间隔区得到的可信宿主预测。这种偏差并不令人担忧，因为我们关注的是相对于其他工具和基因组嵌入的相对性能，而不是绝对的预测能力。  
![image](https://github.com/user-attachments/assets/ce829688-729d-4862-9a8c-dc1dc68628eb)  
### Host prediction model training
![image](https://github.com/user-attachments/assets/dd20d1f2-e5c5-479b-b77a-274a96fb7768)  
![image](https://github.com/user-attachments/assets/8baf025b-b866-4a97-84f1-d09cde97c96d)  
为了适度优化超参数，我们从直观值的集合中抽样，这些值用于编码器层数、解码器隐藏维度、学习率、是否启用分离训练（以70:30的比例分割），以及是否在编码器中允许边缘特定权重。我们没有在编码器层中扩大输入嵌入维度。对于两层前馈解码器网络，我们只选择了小于或等于输入嵌入维度的值作为第一层。第二层的维度则要求严格小于第一层的维度。参见补充表9，了解为每个超参数抽样的值。我们在训练每次迭代时应用相同的随机种子，并根据良好的整体性能和150个训练周期结束时的最低验证损失选择最佳模型。我们定义“良好”的整体性能为验证损失曲线在训练结束时单调递减或保持不变。我们选取了总共4个最佳模型：一个是没有上述改变的CHERRY，另外三个允许上述实施更改并使用不同的基因组嵌入。所有模型都在编码器之后以及每个解码器前馈层之后使用了0.25的dropout。每一层之后我们使用了ReLU激活函数。  
### Host prediction model evaluation
我们使用iPHoP测试数据集（见“宿主预测训练和测试数据集”）评估了iPHoP（v1.3.3）和四个训练过的模型。对于这四个基于图的模型，我们考虑了所有测试病毒-宿主对进行链接预测，并只保留了那些≥75%信心度的，这是iPHoP的最低标准，或者≥90%信心度的。所有病毒-宿主对都被考虑，以便在每个宿主分类等级上实现解析。然而，我们只评估了真实宿主分类是否在信心阈值以上的预测中，因此并非所有预测都被分析。具体来说，我们计算了iPHoP测试数据集中被有信心预测到其真实宿主分类的病毒的比例。

由于在iPHoP测试数据集中明显有一些病毒与vPST训练数据集中的病毒相似（见“平均氨基酸身份（AAI）基因组聚类”），我们使用了几个相似度截止值过滤掉这些病毒，以评估这些相似性对我们解释宿主预测结果的影响。  
Here are the extracted references without line numbers:

1. Roux, S. et al. Ecogenomics and potential biogeochemical impacts of globally abundant ocean viruses. Nature 537, 689–693 (2016).
2. Kieft, K. et al. Virus-associated organosulfur metabolism in human and environmental systems. Cell Rep 36, 109471 (2021).
3. Lin, Z. et al. Evolutionary-scale prediction of atomic-level protein structure with a language model. Science 379, 1123–1130 (2023).
4. Rives, A. et al. Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences. Proceedings of the National Academy of Sciences 118, e2016239118 (2021).
5. Chandra, A., Tünnermann, L., Löfstedt, T. & Gratz, R. Transformer-based deep learning for predicting protein properties in the life sciences. eLife 12, e82819 (2023).
6. Flamholz, Z. N., Biller, S. J. & Kelly, L. Large language models improve annotation of prokaryotic viral proteins. Nat Microbiol 9, 537–549 (2024).
7. Li, B. & Liang, G. ESM-PVP: Identification and classification of phage virion proteins with a large pretrained protein language model and an MLP neural network. Preprint at https://doi.org/10.1101/2023.12.29.573676 (2023).
8. Liu, D., Young, F., Robertson, D. L. & Yuan, K. Prediction of virus-host association using protein language models and multiple instance learning. Preprint at https://doi.org/10.1101/2023.04.07.536023 (2023).
9. Andrade-Martínez, J. S. et al. Computational Tools for the Analysis of Uncultivated Phage Genomes. Microbiol Mol Biol Rev 86, e00004-21.
10. Hwang, Y., Cornman, A. L., Kellogg, E. H., Ovchinnikov, S. & Girguis, P. R. Genomic language model predicts protein co-regulation and function. Nat Commun 15, 2880 (2024).
11. Camargo, A. P. et al. IMG/VR v4: an expanded database of uncultivated virus genomes within a framework of extensive functional, taxonomic, and ecological metadata. Nucleic Acids Res 51, D733–D743 (2023).
12. Lee, J. et al. Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks. in Proceedings of the 36th International Conference on Machine Learning 3744–3753 (PMLR, 2019).
13. Arsomngern, P., Long, C., Suwajanakorn, S. & Nutanong, S. Towards Pointsets Representation Learning via Self-Supervised Learning and Set Augmentation. IEEE Transactions on Pattern Analysis and Machine Intelligence 45, 1201–1216 (2023).
14. Vaswani, A. et al. Attention is All you Need. in Advances in Neural Information Processing Systems vol. 30 (Curran Associates, Inc., 2017).
15. Devlin, J., Chang, M.-W., Lee, K. & Toutanova, K. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Preprint at http://arxiv.org/abs/1810.04805 (2019).
16. Schroff, F., Kalenichenko, D. & Philbin, J. FaceNet: A Unified Embedding for Face Recognition and Clustering. in 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 815–823 (2015). doi:10.1109/CVPR.2015.7298682.
17. Tisza, M. J. & Buck, C. B. A catalog of tens of thousands of viruses from human metagenomes reveals hidden associations with chronic diseases. Proceedings of the National Academy of Sciences 118, e2023202118 (2021).
18. Cook, R. et al. Hybrid assembly of an agricultural slurry virome reveals a diverse and stable community with the potential to alter the metabolism and virulence of veterinary pathogens. Microbiome 9, 65 (2021).
19. Gazitúa, M. C. et al. Potential virus-mediated nitrogen cycling in oxygen-depleted oceanic waters. ISME J 15, 981–998 (2021).
20. Gregory, A. C. et al. Marine DNA Viral Macro- and Microdiversity from Pole to Pole. Cell 177, 1109-1123.e14 (2019).
21. Parks, D. H. et al. GTDB: an ongoing census of bacterial and archaeal diversity through a phylogenetically consistent, rank normalized and complete genome-based taxonomy. Nucleic Acids Research 50, D785–D794 (2022).  
22. Camarillo-Guerrero, L. F., Almeida, A., Rangel-Pineros, G., Finn, R. D. & Lawley, T. D. Massive expansion of human gut bacteriophage diversity. Cell 184, 1098-1109.e9 (2021).  
23. Gregory, A. C. et al. The Gut Virome Database Reveals Age-Dependent Patterns of Virome Diversity in the Human Gut. Cell Host Microbe 28, 724-740.e8 (2020). 
24. Roux, S. et al. IMG/VR v3: an integrated ecological and evolutionary framework for interrogating genomes of uncultivated viruses. Nucleic Acids Research 49, D764–D775 (2021).
25. Michniewski, S. et al. A new family of “megaphages” abundant in the marine environment. ISME COMMUN. 1, 1–4 (2021).
26. ter Horst, A. M. et al. Minnesota peat viromes reveal terrestrial and aquatic niche partitioning for local and global viral populations. Microbiome 9, 233 (2021).
27. Brum, J. R. et al. Patterns and ecological drivers of ocean viral communities. Science 348, 1261498 (2015).
28. Zvyagin, M. et al. GenSLMs: Genome-scale language models reveal SARS-CoV-2 evolutionary dynamics. The International Journal of High Performance Computing Applications 37, 683–705 (2023).
29. Nguyen, E. et al. HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution. in Advances in Neural Information Processing Systems vol. 36 43177–201 (Curran Associates, Inc., 2023).
30. Peng, C., Shang, J., Guan, J., Wang, D. & Sun, Y. ViraLM: Empowering Virus Discovery through the Genome Foundation Model. Preprint at https://doi.org/10.1101/2024.01.30.577935 (2024).
31. Shao, B. A long-context language model for deciphering and generating bacteriophage genomes. Preprint at https://doi.org/10.1101/2023.12.18.572218 (2024).
32. Traag, V. A., Waltman, L. & van Eck, N. J. From Louvain to Leiden: guaranteeing well-connected communities. Sci Rep 9, 5233 (2019).
33. Liu, X., Jiang, H., Gu, Z. & Roberts, J. W. High-resolution view of bacteriophage lambda gene expression by ribosome profiling. Proceedings of the National Academy of Sciences 110, 11928–11933 (2013).
34. Barrio-Hernandez, I. et al. Clustering predicted structures at the scale of the known protein universe. Nature 622, 637–645 (2023).
35. Heinzinger, M. et al. Bilingual Language Model for Protein Sequence and Structure. Preprint at https://doi.org/10.1101/2023.07.23.550085 (2024).
36. Varadi, M. et al. PDBe and PDBe-KB: Providing high-quality, up-to-date and integrated resources of macromolecular structures to support basic and applied research and education. Protein Science 31, e4439 (2022).
37. Gan, L. et al. Capsid Conformational Sampling in HK97 Maturation Visualized by X-Ray Crystallography and Cryo-EM. Structure 14, 1655–1665 (2006).
38. Abramson, J. et al. Accurate structure prediction of biomolecular interactions with AlphaFold 3. Nature 630, 493–500 (2024).
39. Shang, J. & Sun, Y. CHERRY: a Computational metHod for accuratE pRediction of virus–pRokarYotic interactions using a graph encoder–decoder model. Briefings in Bioinformatics 23, bbac182 (2022).
40. Roux, S. et al. iPHoP: An integrated machine learning framework to maximize host prediction for metagenome-derived viruses of archaea and bacteria. PLOS Biology 21, e3002083 (2023).
41. Nguyen, E. et al. Sequence modeling and design from molecular to genome scale with Evo. Preprint at https://doi.org/10.1101/2024.02.27.582234 (2024).
42. Hayes, T. et al. Simulating 500 million years of evolution with a language model. Preprint at https://doi.org/10.1101/2024.07.01.600583 (2024).
43. Center for High Throughput Computing. Center for High Throughput Computing. (2006) doi:10.21231/gnt1-hw21.
44. Sirén, K. et al. Rapid discovery of novel prophages using biological feature engineering and machine learning. NAR Genomics and Bioinformatics 3, lqaa109 (2021).
45. Nayfach, S. et al. CheckV assesses the quality and completeness of metagenome-assembled viral genomes. Nat Biotechnol 39, 578–585 (2021).
46. Skani enables accurate and efficient genome comparison for modern metagenomic datasets. Nat Methods 20, 1633–1634 (2023).
47. Van Dongen, S. Graph Clustering Via a Discrete Uncoupling Process. SIAM J. Matrix Anal. Appl. 30, 121–141 (2008).
48. Larralde, M. Pyrodigal: Python bindings and interface to Prodigal, an efficient method for gene prediction in prokaryotes. Journal of Open Source Software 7, 4296 (2022).
49. Camargo, A. P. et al. Identification of mobile genetic elements with geNomad. Nat Biotechnol 1–10 (2023) doi:10.1038/s41587-023-01953-y.
50. Paszke, A. et al. Automatic differentiation in PyTorch. (2017).
51. Fey, M. & Lenssen, J. E. Fast Graph Representation Learning with PyTorch Geometric. Preprint at http://arxiv.org/abs/1903.02428 (2019).
52. Hendrycks, D. & Gimpel, K. Gaussian Error Linear Units (GELUs). Preprint at https://doi.org/10.48550/arXiv.1606.08415 (2023).
53. Akiba, T., Sano, S., Yanase, T., Ohta, T. & Koyama, M. Optuna: A Next-generation Hyperparameter Optimization Framework. in Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining 2623–2631 (Association for Computing Machinery, 2019). doi:10.1145/3292500.3330701.
54. Rand, K., Grytten, I., Pavlovic, M., Kanduri, C. & Sandve, G. K. BioNumPy: Fast and easy analysis of biological data with Python. Preprint at https://doi.org/10.1101/2022.12.21.521373 (2022).
55. Douze, M. et al. The Faiss library. Preprint at https://doi.org/10.48550/arXiv.2401.08281 (2024).
56. Steinegger, M. & Söding, J. MMseqs2 enables sensitive protein sequence searching for the analysis of massive data sets. Nat Biotechnol 35, 1026–1028 (2017).
57. Nayfach, S. et al. Metagenomic compendium of 189,680 DNA viruses from the human gut microbiome. Nat Microbiol 6, 960–970 (2021).
58. Terzian, P. et al. PHROG: families of prokaryotic virus proteins clustered using remote homology. NAR Genomics and Bioinformatics 3, lqab067 (2021).
59. Zhang, Y. & Skolnick, J. TM-align: a protein structure alignment algorithm based on the TM-score. Nucleic Acids Res 33, 2302–2309 (2005).
60. McInnes, L., Healy, J. & Melville, J. UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction. Preprint at http://arxiv.org/abs/1802.03426 (2020).
61. Kipf, T. N. & Welling, M. Semi-Supervised Classification with Graph Convolutional Networks. Preprint at http://arxiv.org/abs/1609.02907 (2017).
62. Mihara, T. et al. Linking Virus Genomes with Host Taxonomy. Viruses 8, 66 (2016).
63. Morris, C. et al. Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks. Preprint at http://arxiv.org/abs/1810.02244 (2021).











